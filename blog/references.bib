@online{haarnojaSoftActorCriticAlgorithms2019,
  title = {Soft {{Actor-Critic Algorithms}} and {{Applications}}},
  author = {Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  date = {2019-01-29},
  eprint = {1812.05905},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1812.05905},
  url = {http://arxiv.org/abs/1812.05905},
  urldate = {2025-10-15},
}

@online{haarnojaSoftActorCriticOffPolicy2018,
  title = {Soft {{Actor-Critic}}: {{Off-Policy Maximum Entropy Deep Reinforcement Learning}} with a {{Stochastic Actor}}},
  shorttitle = {Soft {{Actor-Critic}}},
  author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  date = {2018-08-08},
  eprint = {1801.01290},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1801.01290},
  url = {http://arxiv.org/abs/1801.01290},
  urldate = {2025-08-28},
}

@online{lillicrapContinuousControlDeep2015,
  title = {Continuous Control with Deep Reinforcement Learning},
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  date = {2015},
  doi = {10.48550/ARXIV.1509.02971},
  url = {https://arxiv.org/abs/1509.02971},
  urldate = {2025-10-24},
}

@InProceedings{pmlr-v80-fujimoto18a,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author =       {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1587--1596},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/fujimoto18a.html},
}


@InProceedings{pmlr-v37-schulman15,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schulman15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/schulman15.html},
}

@online{schulmanProximalPolicyOptimization2017c,
  title = {Proximal {{Policy Optimization Algorithms}}},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  date = {2017},
  doi = {10.48550/ARXIV.1707.06347},
  url = {https://arxiv.org/abs/1707.06347},
  urldate = {2025-10-24},
}


@InProceedings{pmlr-v48-mniha16,
  title = 	 {Asynchronous Methods for Deep Reinforcement Learning},
  author = 	 {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1928--1937},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/mniha16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/mniha16.html},
}

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K and others},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@InProceedings{pmlr-v70-haarnoja17a,
  title = 	 {Reinforcement Learning with Deep Energy-Based Policies},
  author =       {Tuomas Haarnoja and Haoran Tang and Pieter Abbeel and Sergey Levine},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1352--1361},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/haarnoja17a/haarnoja17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/haarnoja17a.html},
}

@inproceedings{NIPS2010_091d584f,
 author = {Hasselt, Hado},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Double Q-learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2010/file/091d584fced301b442654dd8c23b3fc9-Paper.pdf},
 volume = {23},
 year = {2010}
}

